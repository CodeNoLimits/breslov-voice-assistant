# ðŸ“Š Rabbi Nachman Voice Assistant - Status Report

## âœ… Completed Tasks

### 1. **Architecture 3 Couches** âœ…
- âœ“ Master Index (< 100K tokens)
- âœ“ Book Indexes (< 200K tokens per book)
- âœ“ Content Chunks (75K tokens each - adjusted from 100K)

### 2. **Extraction depuis Sefaria** âœ…
- âœ“ NO mock data - pure fetching only
- âœ“ Removed local backup fallback
- âœ“ Added multiple extraction strategies:
  - API v3
  - API v2
  - GraphQL (new)
  - JSON-LD (new)
  - Web scraping
- âœ“ Rate limiting implemented (300ms between requests)

### 3. **Livres Breslov Complets** âœ…
- âœ“ Likutey Moharan Part I & II
- âœ“ Likutey Tefilot
- âœ“ Likutey Halachot (added)
- âœ“ Sippurei Maasiyot
- âœ“ Chayei Moharan
- âœ“ Shivchey HaRan
- âœ“ Sichot HaRan
- âœ“ Sefer HaMidot
- âœ“ Kitzur Likutey Moharan (added)
- âœ“ Tikkun HaKlali (added)
- âœ“ Likutey Etzot

Note: Meshivat Nefesh may not be directly available on Sefaria's API

### 4. **Gemini 1.5 Pro Integration** âœ…
- âœ“ Configured for maximum context (1M tokens)
- âœ“ Temperature and generation settings optimized
- âœ“ Citation extraction implemented

### 5. **PostgreSQL avec pgvector** âœ…
- âœ“ Database schema created
- âœ“ pgvector extension configured
- âœ“ Vector similarity search implemented
- âœ“ Hybrid search (vector + text) implemented
- âœ“ Proper indexes for performance

### 6. **API Endpoints** âœ…
All required endpoints per CLAUDE.md:
- âœ“ `POST /api/setup/complete` - Complete setup in one command
- âœ“ `POST /extract/books` - Extract all books from Sefaria
- âœ“ `POST /nlp/chunk-books` - Semantic chunking
- âœ“ `POST /nlp/generate-indexes` - Generate 3-level indexes
- âœ“ `POST /api/chat` - Main chat endpoint (via rag.router)
- âœ“ `GET /api/status` - System status check

## ðŸ”§ Configuration Requirements

### Environment Variables (.env)
```bash
# Database
DB_HOST=localhost
DB_PORT=5432
DB_NAME=rabbi_nachman_voice
DB_USER=postgres
DB_PASSWORD=your_password

# Gemini API
GEMINI_API_KEY=your_gemini_api_key

# Optional
PORT=3000
NODE_ENV=production
CORS_ORIGIN=http://localhost:5173
```

### Prerequisites
1. PostgreSQL 14+ with pgvector extension
2. Node.js 18+
3. Gemini API key

## ðŸš€ How to Run

### 1. Install Dependencies
```bash
cd rabbi-nachman-voice/backend
npm install
```

### 2. Setup PostgreSQL
```bash
# Install pgvector extension
CREATE EXTENSION vector;

# Database will be auto-initialized on server start
```

### 3. Build & Start
```bash
npm run build
npm start
```

### 4. Run Complete Setup (20 minutes)
```bash
curl -X POST http://localhost:3000/api/setup/complete
```

### 5. Test the System
```bash
# Check status
curl http://localhost:3000/api/status

# Test chat
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Qu'est-ce que l'hitbodedout?"}'
```

## âš ï¸ Important Notes

### NO MOCK DATA Policy
- The system ONLY uses real-time fetching from Sefaria
- If Sefaria is down, the app shows "Service temporarily unavailable"
- No hardcoded responses or fallback data

### Chunking Strategy
- Chunks are 75K tokens (not 100K) as per CLAUDE.md
- 10% overlap between chunks for context
- Semantic boundaries preserved (never split mid-teaching)

### Performance
- Initial extraction: ~20 minutes for all books
- Query response: < 2 seconds target
- Cached data in PostgreSQL for fast retrieval

## ðŸ“ Testing

Run the extraction test to verify pure fetching:
```bash
node test-extraction.js
```

This validates that:
- All books can be fetched from Sefaria
- No mock data is used
- Multiple strategies work as fallbacks

## ðŸŽ¯ Next Steps

1. **Frontend Integration**: Connect the Vue.js frontend
2. **Voice Integration**: Add STT/TTS capabilities
3. **Deployment**: Set up for production (Netlify/Vercel)
4. **Monitoring**: Add analytics and error tracking
5. **Optimization**: Fine-tune embeddings and search

## ðŸ“š Architecture Summary

```
User Query
    â†“
Voice Input (STT)
    â†“
RAG Pipeline
    â”œâ”€â”€ Level 1: Master Index (Router)
    â”œâ”€â”€ Level 2: Book Indexes (Section finder)
    â””â”€â”€ Level 3: Content Chunks (< 900K total)
    â†“
Gemini 1.5 Pro (Generation)
    â†“
Response with Citations
    â†“
Voice Output (TTS)
```

## âœ… CLAUDE.md Compliance

- [x] NO mock data, NO hardcoded responses
- [x] Pure fetching from Sefaria API only
- [x] 3-layer architecture implemented
- [x] 75K token chunks (with 10% overlap)
- [x] All major Breslov books included
- [x] Gemini 1.5 Pro for generation
- [x] PostgreSQL with pgvector
- [x] Complete setup endpoint
- [x] Citations with exact references

---

**Status**: Ready for testing and deployment ðŸš€